{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pQCOmISAQBu"
      },
      "source": [
        "## Enabling and testing the TPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpvUOuC3j27n",
        "outputId": "23c86f33-c986-42a7-84df-dcd951d65b38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensorflow version 2.15.0\n"
          ]
        }
      ],
      "source": [
        "import datetime\n",
        "import functools\n",
        "import math\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "# %load_ext tensorboard\n",
        "\n",
        "print(\"Tensorflow version \" + tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFIMfPmgQa0h",
        "outputId": "a0404607-c377-4d62-bb49-c90d689382ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LogicalDevice(name='/device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ],
      "source": [
        "tf.debugging.set_log_device_placement(False)\n",
        "GPU = tf.config.list_logical_devices('GPU')\n",
        "GPU_STRATEGY = tf.distribute.MirroredStrategy(GPU)\n",
        "\n",
        "print(GPU)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0t1jfsJlM3SX"
      },
      "source": [
        "## Defining The Metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Z74MlibMWnu"
      },
      "outputs": [],
      "source": [
        "# META ########################################################################\n",
        "\n",
        "N_DEPTH = 3 # D\n",
        "N_TOKEN_DIM = 4 # G\n",
        "N_ENCODING_DIM = 256 # U\n",
        "N_EMBEDDING_DIM = N_ENCODING_DIM # E\n",
        "N_LATENT_DIM = N_EMBEDDING_DIM # L\n",
        "\n",
        "N_EPOCHS = 32\n",
        "N_EPOCHS_RAMPUP = 16\n",
        "N_EPOCHS_SUSTAIN = 0\n",
        "\n",
        "N_BATCH = 128 # number of samples per batch\n",
        "N_SAMPLE = 128 # number of characters per sample (=> N_TOKEN_DIM * N_SAMPLE int per sample)\n",
        "\n",
        "R_MIN = 0.0001\n",
        "R_MAX = 0.001\n",
        "R_EXP = .8\n",
        "\n",
        "VERSION = 'tokun-4x4-keras-1M700K'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEyFtkcFNGe4"
      },
      "source": [
        "## Loading The Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4a3SQUQHNJ6M"
      },
      "outputs": [],
      "source": [
        "# DATA ########################################################################\n",
        "\n",
        "# DATA_TRAIN, DATA_TEST = tfds.load('mlqadd', split=['train', 'test'], as_supervised=True, shuffle_files=True, data_dir='~/.cache/tensorflow/', builder_kwargs={'train_lang': ['en'], 'test_lang': ['es']})\n",
        "LANG = ['ar', 'de', 'en', 'es', 'hi', 'vi', 'zh']\n",
        "DATA = {__l: tfds.load('mlqa/' + __l, split='test', as_supervised=False, shuffle_files=True, data_dir='~/.cache/tensorflow/', batch_size=N_BATCH) for __l in LANG}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdWFiijDnwa4"
      },
      "source": [
        "## LAYERS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1HZhkT9Rtz4"
      },
      "outputs": [],
      "source": [
        "# EMBEDDING ###################################################################\n",
        "\n",
        "class PositionalEmbedding(tf.keras.layers.Layer):\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_axis: int=1, # axis of the sequence\n",
        "        output_axis: int=-1, # axis of the embedding\n",
        "        **kwargs\n",
        "    ):\n",
        "        super(PositionalEmbedding, self).__init__(**kwargs)\n",
        "        self._input_axis = input_axis\n",
        "        self._output_axis = output_axis\n",
        "        self._kernel = None\n",
        "\n",
        "    def build(self, input_shape: tuple):\n",
        "        # shape\n",
        "        __axes = [self._input_axis % len(input_shape), self._output_axis % len(input_shape)]\n",
        "        __shape = [(__d if __i in __axes else 1) for __i, __d in enumerate(list(input_shape))]\n",
        "        # init values\n",
        "        __kernel_init = tf.keras.initializers.GlorotNormal()\n",
        "        # register the weights\n",
        "        self._kernel = self.add_weight(name=\"kernel\", shape=__shape, initializer=__kernel_init)\n",
        "        # notify the model\n",
        "        self.built = True\n",
        "\n",
        "    def call(self, inputs: tf.Tensor):\n",
        "        return inputs + self._kernel # each index in the sequence axis has a dedicated bias (different from dense bias)\n",
        "\n",
        "# RESHAPING ###################################################################\n",
        "\n",
        "def _normalize_shape(shape: list) -> list:\n",
        "    return [-1 if __d is None else __d for __d in shape]\n",
        "\n",
        "def _normalize_dim(dim: int) -> int:\n",
        "    return -1 if (dim is None or dim < 0) else dim\n",
        "\n",
        "def _multiply_dim(dim_l: int, dim_r: int) -> int:\n",
        "    return -1 if (dim_l == -1 or dim_r == -1) else dim_l * dim_r\n",
        "\n",
        "def _divide_dim(dim_l: int, dim_r: int) -> int:\n",
        "    return -1 if (dim_l == -1 or dim_r == -1) else dim_l // dim_r\n",
        "\n",
        "class Divide(tf.keras.layers.Layer):\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_axis: int, # relative to the NEW shape / rank\n",
        "        output_axis: int, # same\n",
        "        factor: int,\n",
        "        insert: bool=False,\n",
        "        **kwargs\n",
        "    ) -> None:\n",
        "        super(Divide, self).__init__(**kwargs)\n",
        "        self._input_axis = input_axis\n",
        "        self._output_axis = output_axis\n",
        "        self._factor = factor\n",
        "        self._insert = insert\n",
        "\n",
        "    def call(self, inputs: tf.Tensor) -> tf.Tensor:\n",
        "        # infer the dimension of the symbolic axis\n",
        "        __shape = _normalize_shape(list(inputs.shape))\n",
        "        # rank, according to the new shape\n",
        "        __rank = len(__shape) + int(self._insert)\n",
        "        # axes, taken from the new shape\n",
        "        __axis0 = self._input_axis % __rank\n",
        "        __axis1 = self._output_axis % __rank\n",
        "        # option to group data on a new axistho i do it with other\n",
        "        if self._insert: __shape.insert(__axis1, 1)\n",
        "        # move data from axis 0 to axis 1\n",
        "        __shape[__axis0] = _divide_dim(__shape[__axis0], self._factor)\n",
        "        __shape[__axis1] = _multiply_dim(__shape[__axis1], self._factor)\n",
        "        return tf.reshape(tensor=inputs, shape=__shape)\n",
        "\n",
        "class Merge(tf.keras.layers.Layer):\n",
        "    def __init__(\n",
        "        self,\n",
        "        left_axis: int=-2,\n",
        "        right_axis: int=-1,\n",
        "        left: bool=True,\n",
        "        **kwargs\n",
        "    ) -> None:\n",
        "        super(Merge, self).__init__(**kwargs)\n",
        "        self._left_axis = left_axis\n",
        "        self._right_axis = right_axis\n",
        "        self._left = left\n",
        "\n",
        "    def call(self, inputs: tf.Tensor) -> tf.Tensor:\n",
        "        # infer the dimension of the symbolic axis\n",
        "        __shape = _normalize_shape(list(inputs.shape))\n",
        "        __rank = len(__shape)\n",
        "        # target axes\n",
        "        __axis_l = self._left_axis % __rank\n",
        "        __axis_r = self._right_axis % __rank\n",
        "        # new axis\n",
        "        __dim = _multiply_dim(__shape[__axis_l], __shape[__axis_r])\n",
        "        __axis_k = __axis_l if self._left else __axis_r # kept axis\n",
        "        __axis_d = __axis_r if self._left else __axis_l # deleted axis\n",
        "        # new shape\n",
        "        __shape[__axis_k] = __dim\n",
        "        __shape.pop(__axis_d)\n",
        "        # actually merge the two axes\n",
        "        return tf.reshape(tensor=inputs, shape=__shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgceZVOon0Mi"
      },
      "source": [
        "## Blocks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ITuRAod-n6Lm"
      },
      "outputs": [],
      "source": [
        "# ENCODING BLOCKS #############################################################\n",
        "\n",
        "class TokenizeBlock(tf.keras.layers.Layer):\n",
        "    def __init__(\n",
        "        self,\n",
        "        left_axis: int=-2,\n",
        "        right_axis: int=-1,\n",
        "        token_dim: int=4,\n",
        "        latent_dim: int=256,\n",
        "        attention: bool=False,\n",
        "        **kwargs\n",
        "    ) -> None:\n",
        "        super(TokenizeBlock, self).__init__(**kwargs)\n",
        "        # layers\n",
        "        self._divide = Divide(input_axis=0, output_axis=1, factor=token_dim, insert=True, name='group') # (B * G, E) => (B, G, E)\n",
        "        self._embedding = PositionalEmbedding(input_axis=left_axis, output_axis=right_axis, name='position') # (B, G, E) + (1, G, E)\n",
        "        self._attention = tf.keras.layers.Attention(use_scale=False, score_mode='dot', dropout=0., seed=None, name='attention') if attention else None # (B, G, E) + (B, G, E) * (B, E, G) * (B, G, E)\n",
        "        self._merge = Merge(left_axis=left_axis, right_axis=right_axis, left=True, name='merging') # (B, G, E) => (B, G * E)\n",
        "        self._dense = tf.keras.layers.Dense(units=latent_dim, activation='relu', use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', name='compression') # (B, G * E) => (B, L), typically L = E\n",
        "\n",
        "    def call(self, inputs: tf.Tensor) -> tf.Tensor:\n",
        "        __t = self._embedding(self._divide(inputs))\n",
        "        __t = self._attention([__t, __t, __t], return_attention_scores=False, use_causal_mask=False) if self._attention else __t\n",
        "        return self._dense(self._merge(__t))\n",
        "\n",
        "# DECODING BLOCKS #############################################################\n",
        "\n",
        "class DetokenizeBlock(tf.keras.layers.Layer):\n",
        "    def __init__(\n",
        "        self,\n",
        "        token_dim: int=4,\n",
        "        embedding_dim: int=256,\n",
        "        attention: bool=False,\n",
        "        **kwargs\n",
        "    ) -> None:\n",
        "        super(DetokenizeBlock, self).__init__(**kwargs)\n",
        "        # layers\n",
        "        self._dense = tf.keras.layers.Dense(units=token_dim * embedding_dim, activation='relu', use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', name='decompression') # (B, L) => (B, G * E), typically L = E\n",
        "        self._divide = Divide(input_axis=-2, output_axis=-1, insert=True, factor=embedding_dim, name='split') # (B, G * E) => (B, G, E)\n",
        "        self._attention = tf.keras.layers.Attention(use_scale=False, score_mode='dot', dropout=0., seed=None, name='attention') if attention else None # (B, G, E) + (B, G, E) * (B, E, G) * (B, G, E)\n",
        "        self._merge = Merge(left_axis=0, right_axis=1, left=True) # (B, G, E) => (B * G, E)\n",
        "\n",
        "    def call(self, inputs: tf.Tensor) -> tf.Tensor:\n",
        "        __t = self._divide(self._dense(inputs))\n",
        "        __t = self._attention([__t, __t, __t], return_attention_scores=False, use_causal_mask=False) if self._attention else __t\n",
        "        return self._merge(__t)\n",
        "\n",
        "# HEAD BLOCK ##################################################################\n",
        "\n",
        "class HeadBlock(tf.keras.layers.Layer):\n",
        "    def __init__(\n",
        "        self,\n",
        "        encoding_dim: int=256,\n",
        "        **kwargs\n",
        "    ) -> None:\n",
        "        super(HeadBlock, self).__init__(**kwargs)\n",
        "        # layers\n",
        "        self._dense = tf.keras.layers.Dense(units=encoding_dim, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', name='project-head') # (..., G, E) => (..., G, U), typically U = E\n",
        "        self._softmax = tf.keras.layers.Softmax(axis=-1, name='softmax') # (..., G, U)\n",
        "\n",
        "    def call(self, inputs: tf.Tensor) -> tf.Tensor:\n",
        "        return self._softmax(self._dense(inputs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S39n2JmXG6yv"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T0upuSDyELmZ"
      },
      "outputs": [],
      "source": [
        "# ENCODER #####################################################################\n",
        "\n",
        "class Encoder(tf.keras.models.Model):\n",
        "    def __init__(self, depth: int, token_dim: int, encoding_dim: int, embedding_dim: int, latent_dim: int, batch_dim: int=None, attention: bool=False, **kwargs) -> None:\n",
        "        super(Encoder, self).__init__(**kwargs)\n",
        "        self._encoder = tf.keras.Sequential([\n",
        "            tf.keras.Input(shape=(encoding_dim,), batch_size=batch_dim, name='input'), # (B * G ^ D, U)\n",
        "            tf.keras.layers.Dense(units=embedding_dim, activation=None, use_bias=False, kernel_initializer='glorot_uniform', bias_initializer=None, name='embed-1'),] # (B * G ^ D, U) => (B * G ^ D, E)\n",
        "            + [TokenizeBlock(left_axis=-2, right_axis=-1, token_dim=token_dim, latent_dim=latent_dim, attention=attention, name='tokenize' + (__i + 1) * '-4') for __i in range(depth)]) # (B * G ^ i, E) => (B * G ^ (i-1), E)\n",
        "\n",
        "    def call(self, x: tf.Tensor) -> tf.Tensor:\n",
        "        return self._encoder(x)\n",
        "\n",
        "# DECODER #####################################################################\n",
        "\n",
        "class Decoder(tf.keras.models.Model):\n",
        "    def __init__(self, depth: int, token_dim: int, encoding_dim: int, embedding_dim: int, latent_dim: int, batch_dim: int=None, attention: bool=False, **kwargs) -> None:\n",
        "        super(Decoder, self).__init__(**kwargs)\n",
        "        self._decoder = tf.keras.Sequential(\n",
        "            [tf.keras.Input(shape=(latent_dim,), batch_size=batch_dim, name='input')] # (B, E)\n",
        "            + [DetokenizeBlock(token_dim=token_dim, embedding_dim=embedding_dim, attention=attention, name='detokenize' + (depth - __i) * '-4') for __i in range(depth)] # (B * G ^ i, E) => (B * G ^ (i+1), E)\n",
        "            + [HeadBlock(encoding_dim=encoding_dim, name='project-head')]) # (B * G ^ D, E) => (B * G ^ D, U)\n",
        "\n",
        "    def call(self, x: tf.Tensor) -> tf.Tensor:\n",
        "        return self._decoder(x)\n",
        "\n",
        "# VAE #########################################################################\n",
        "\n",
        "class AutoEncoder(tf.keras.models.Model):\n",
        "    def __init__(self, depth: int, token_dim: int, encoding_dim: int, embedding_dim: int, latent_dim: int, batch_dim: int=None, attention: bool=False, **kwargs) -> None:\n",
        "        super(AutoEncoder, self).__init__(**kwargs)\n",
        "        self._encoder = Encoder(depth=depth, token_dim=token_dim, encoding_dim=encoding_dim, embedding_dim=embedding_dim, latent_dim=latent_dim, batch_dim=batch_dim, attention=attention)\n",
        "        self._decoder = Decoder(depth=depth, token_dim=token_dim, encoding_dim=encoding_dim, embedding_dim=embedding_dim, latent_dim=latent_dim, batch_dim=batch_dim, attention=attention)\n",
        "\n",
        "    def call(self, x: tf.Tensor) -> tf.Tensor:\n",
        "        return self._decoder(self._encoder(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iEpY1-vFIFX7"
      },
      "outputs": [],
      "source": [
        "with GPU_STRATEGY.scope():\n",
        "  MODEL = AutoEncoder(depth=N_DEPTH, token_dim=N_TOKEN_DIM, encoding_dim=N_ENCODING_DIM, embedding_dim=N_EMBEDDING_DIM, latent_dim=N_LATENT_DIM, batch_dim=None, attention=True)\n",
        "  MODEL.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=R_MAX),\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False, label_smoothing=0., axis=-1, reduction=tf.keras.losses.Reduction.SUM_OVER_BATCH_SIZE, name='loss'),\n",
        "    metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cheN52OEchs"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uintcdw8KwOc"
      },
      "outputs": [],
      "source": [
        "# CONTROL #####################################################################\n",
        "\n",
        "def learning_rate_hokusai(epoch: int, lr_min: float, lr_max: float, lr_exp: float, rampup: int, sustain: int) -> float:\n",
        "    __lr = lr_min\n",
        "    if epoch < rampup:\n",
        "        __lr = lr_min + (epoch * (lr_max - lr_min) / rampup)\n",
        "    elif epoch < rampup + sustain:\n",
        "        __lr = lr_max\n",
        "    else:\n",
        "        __lr = lr_min + (lr_max - lr_min) * lr_exp ** (epoch - rampup - sustain)\n",
        "    return __lr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9vnCKf88Na2E"
      },
      "outputs": [],
      "source": [
        "# PREPROCESS ##################################################################\n",
        "\n",
        "def shape(layer_count: int, group_size: int, flatten: bool=False) -> list:\n",
        "    return [-1] + (1 - int(flatten)) * layer_count * [group_size]\n",
        "\n",
        "def _tokenize_scalar(text: str, layer_count: int=1, group_size: int=4, flatten: bool=False) -> tf.Tensor:\n",
        "    __mod = group_size ** layer_count\n",
        "    __bytes = list(text.encode('utf-32-be'))\n",
        "    __shape = shape(layer_count=layer_count, group_size=group_size, flatten=flatten)\n",
        "    __padding = (-len(__bytes) % __mod) * [0]\n",
        "    __tensor = tf.convert_to_tensor(value=__bytes + __padding, dtype=tf.dtypes.int32) # uint8 is not allowed\n",
        "    return tf.reshape(tensor=__tensor, shape=__shape)\n",
        "\n",
        "def tokenize(data: tf.Tensor, layer_count: int=1, group_size: int=4, sample_size: int=64, flatten: bool=False) -> tf.Tensor:\n",
        "    # make sure each sample has a length multiple of G ** L = T, the token dim\n",
        "    __mod = group_size ** layer_count\n",
        "    __dim = math.ceil(4 * sample_size / __mod) * __mod # factor 4 because of the UTF-32 encoding\n",
        "    # output shape\n",
        "    __shape = shape(layer_count=layer_count, group_size=group_size, flatten=flatten)\n",
        "    # Decode bytes from UTF-8\n",
        "    __bytes = tf.strings.unicode_transcode(input=data, input_encoding='UTF-8', output_encoding='UTF-32-BE') # (B,)\n",
        "    # Decode byte strings to arrays of integers\n",
        "    __ints = tf.io.decode_raw(__bytes, out_type=tf.uint8, fixed_length=__dim) # (B, 4 * S)\n",
        "    # group the characters into tokens\n",
        "    return tf.reshape(tensor=__ints, shape=__shape) # for example (-1, G, G, G) the first dimension is not B\n",
        "\n",
        "def preprocess(dataset: tf.data.Dataset, key: str='context', layer_count: int=1, group_size: int=4, sample_size: int=64, flatten: bool=False) -> tf.data.Dataset:\n",
        "    # from UTF-8 bytes scalar to UTF-32-BE int tensor\n",
        "    __dataset = dataset.map(lambda x: tokenize(data=x[key], layer_count=layer_count, group_size=group_size, sample_size=sample_size, flatten=flatten))\n",
        "    # one-hot encoding of UTF-32 bytes\n",
        "    __dataset = __dataset.map(lambda x: tf.one_hot(indices=x, depth=256, axis=-1))\n",
        "    # produce (input, target) tuples for supervised training, instead of a single tensor X\n",
        "    return __dataset.map(lambda x: (x,x))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA = {__l: preprocess(dataset=__d, key='context', layer_count=N_DEPTH, group_size=N_TOKEN_DIM, sample_size=N_SAMPLE, flatten=True) for __l, __d in DATA.items()}"
      ],
      "metadata": {
        "id": "Gp2WitYVhs8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9e3KMoxKn1Bd"
      },
      "outputs": [],
      "source": [
        "# SAVE ########################################################################\n",
        "\n",
        "# log path\n",
        "LOGPATH = os.path.join('.logs/', VERSION, datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "SUMMARY = tf.summary.create_file_writer(LOGPATH)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "beTpALmzFdu1",
        "outputId": "624afe6c-9b79-4010-a0e5-3b5350830add"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1/32\n",
            "291/291 - 28s - loss: 1.2961 - accuracy: 0.7825 - val_loss: 1.9891 - val_accuracy: 0.7194 - lr: 0.0010 - 28s/epoch - 97ms/step\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.0008200000000000001.\n",
            "Epoch 2/32\n",
            "291/291 - 25s - loss: 0.6035 - accuracy: 0.8498 - lr: 8.2000e-04 - 25s/epoch - 84ms/step\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.0006760000000000002.\n",
            "Epoch 3/32\n",
            "291/291 - 24s - loss: 0.4795 - accuracy: 0.8774 - lr: 6.7600e-04 - 24s/epoch - 83ms/step\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.0005608000000000001.\n",
            "Epoch 4/32\n",
            "291/291 - 24s - loss: 0.3901 - accuracy: 0.8976 - lr: 5.6080e-04 - 24s/epoch - 84ms/step\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.00046864000000000004.\n",
            "Epoch 5/32\n",
            "291/291 - 28s - loss: 0.3315 - accuracy: 0.9117 - val_loss: 1.1472 - val_accuracy: 0.8595 - lr: 4.6864e-04 - 28s/epoch - 97ms/step\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.0003949120000000001.\n",
            "Epoch 6/32\n",
            "291/291 - 24s - loss: 0.2902 - accuracy: 0.9226 - lr: 3.9491e-04 - 24s/epoch - 84ms/step\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.0003359296000000001.\n",
            "Epoch 7/32\n",
            "291/291 - 24s - loss: 0.2631 - accuracy: 0.9301 - lr: 3.3593e-04 - 24s/epoch - 82ms/step\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.00028874368000000004.\n",
            "Epoch 8/32\n",
            "291/291 - 24s - loss: 0.2432 - accuracy: 0.9353 - lr: 2.8874e-04 - 24s/epoch - 83ms/step\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.00025099494400000007.\n",
            "Epoch 9/32\n",
            "291/291 - 27s - loss: 0.2273 - accuracy: 0.9395 - val_loss: 0.7541 - val_accuracy: 0.8830 - lr: 2.5099e-04 - 27s/epoch - 93ms/step\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.00022079595520000007.\n",
            "Epoch 10/32\n",
            "291/291 - 24s - loss: 0.2148 - accuracy: 0.9428 - lr: 2.2080e-04 - 24s/epoch - 84ms/step\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 0.00019663676416000007.\n",
            "Epoch 11/32\n",
            "291/291 - 24s - loss: 0.2045 - accuracy: 0.9455 - lr: 1.9664e-04 - 24s/epoch - 82ms/step\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 0.00017730941132800004.\n",
            "Epoch 12/32\n",
            "291/291 - 24s - loss: 0.1962 - accuracy: 0.9478 - lr: 1.7731e-04 - 24s/epoch - 81ms/step\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 0.00016184752906240002.\n",
            "Epoch 13/32\n",
            "291/291 - 28s - loss: 0.1892 - accuracy: 0.9497 - val_loss: 0.6663 - val_accuracy: 0.8932 - lr: 1.6185e-04 - 28s/epoch - 96ms/step\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 0.00014947802324992004.\n",
            "Epoch 14/32\n",
            "291/291 - 23s - loss: 0.1831 - accuracy: 0.9514 - lr: 1.4948e-04 - 23s/epoch - 81ms/step\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 0.00013958241859993604.\n",
            "Epoch 15/32\n",
            "291/291 - 24s - loss: 0.1777 - accuracy: 0.9529 - lr: 1.3958e-04 - 24s/epoch - 84ms/step\n",
            "\n",
            "Epoch 16: LearningRateScheduler setting learning rate to 0.00013166593487994884.\n",
            "Epoch 16/32\n",
            "291/291 - 24s - loss: 0.1733 - accuracy: 0.9540 - lr: 1.3167e-04 - 24s/epoch - 84ms/step\n",
            "\n",
            "Epoch 17: LearningRateScheduler setting learning rate to 0.00012533274790395906.\n",
            "Epoch 17/32\n",
            "291/291 - 27s - loss: 0.1691 - accuracy: 0.9552 - val_loss: 0.6333 - val_accuracy: 0.8984 - lr: 1.2533e-04 - 27s/epoch - 93ms/step\n",
            "\n",
            "Epoch 18: LearningRateScheduler setting learning rate to 0.00012026619832316726.\n",
            "Epoch 18/32\n",
            "291/291 - 24s - loss: 0.1655 - accuracy: 0.9561 - lr: 1.2027e-04 - 24s/epoch - 83ms/step\n",
            "\n",
            "Epoch 19: LearningRateScheduler setting learning rate to 0.0001162129586585338.\n",
            "Epoch 19/32\n",
            "291/291 - 24s - loss: 0.1623 - accuracy: 0.9570 - lr: 1.1621e-04 - 24s/epoch - 83ms/step\n",
            "\n",
            "Epoch 20: LearningRateScheduler setting learning rate to 0.00011297036692682704.\n",
            "Epoch 20/32\n",
            "291/291 - 24s - loss: 0.1590 - accuracy: 0.9579 - lr: 1.1297e-04 - 24s/epoch - 83ms/step\n",
            "\n",
            "Epoch 21: LearningRateScheduler setting learning rate to 0.00011037629354146163.\n",
            "Epoch 21/32\n",
            "291/291 - 27s - loss: 0.1559 - accuracy: 0.9587 - val_loss: 0.6102 - val_accuracy: 0.9019 - lr: 1.1038e-04 - 27s/epoch - 92ms/step\n",
            "\n",
            "Epoch 22: LearningRateScheduler setting learning rate to 0.00010830103483316931.\n",
            "Epoch 22/32\n",
            "291/291 - 24s - loss: 0.1538 - accuracy: 0.9593 - lr: 1.0830e-04 - 24s/epoch - 84ms/step\n",
            "\n",
            "Epoch 23: LearningRateScheduler setting learning rate to 0.00010664082786653545.\n",
            "Epoch 23/32\n",
            "291/291 - 24s - loss: 0.1513 - accuracy: 0.9600 - lr: 1.0664e-04 - 24s/epoch - 83ms/step\n",
            "\n",
            "Epoch 24: LearningRateScheduler setting learning rate to 0.00010531266229322837.\n",
            "Epoch 24/32\n",
            "291/291 - 24s - loss: 0.1488 - accuracy: 0.9606 - lr: 1.0531e-04 - 24s/epoch - 82ms/step\n",
            "\n",
            "Epoch 25: LearningRateScheduler setting learning rate to 0.00010425012983458269.\n",
            "Epoch 25/32\n",
            "291/291 - 27s - loss: 0.1470 - accuracy: 0.9611 - val_loss: 0.5885 - val_accuracy: 0.9044 - lr: 1.0425e-04 - 27s/epoch - 94ms/step\n",
            "\n",
            "Epoch 26: LearningRateScheduler setting learning rate to 0.00010340010386766616.\n",
            "Epoch 26/32\n",
            "291/291 - 25s - loss: 0.1443 - accuracy: 0.9618 - lr: 1.0340e-04 - 25s/epoch - 84ms/step\n",
            "\n",
            "Epoch 27: LearningRateScheduler setting learning rate to 0.00010272008309413293.\n",
            "Epoch 27/32\n",
            "291/291 - 24s - loss: 0.1426 - accuracy: 0.9623 - lr: 1.0272e-04 - 24s/epoch - 82ms/step\n",
            "\n",
            "Epoch 28: LearningRateScheduler setting learning rate to 0.00010217606647530634.\n",
            "Epoch 28/32\n",
            "291/291 - 24s - loss: 0.1407 - accuracy: 0.9628 - lr: 1.0218e-04 - 24s/epoch - 82ms/step\n",
            "\n",
            "Epoch 29: LearningRateScheduler setting learning rate to 0.00010174085318024508.\n",
            "Epoch 29/32\n",
            "291/291 - 27s - loss: 0.1389 - accuracy: 0.9633 - val_loss: 0.5653 - val_accuracy: 0.9072 - lr: 1.0174e-04 - 27s/epoch - 93ms/step\n",
            "\n",
            "Epoch 30: LearningRateScheduler setting learning rate to 0.00010139268254419606.\n",
            "Epoch 30/32\n",
            "291/291 - 24s - loss: 0.1384 - accuracy: 0.9633 - lr: 1.0139e-04 - 24s/epoch - 83ms/step\n",
            "\n",
            "Epoch 31: LearningRateScheduler setting learning rate to 0.00010111414603535684.\n",
            "Epoch 31/32\n",
            "291/291 - 24s - loss: 0.1354 - accuracy: 0.9642 - lr: 1.0111e-04 - 24s/epoch - 83ms/step\n",
            "\n",
            "Epoch 32: LearningRateScheduler setting learning rate to 0.00010089131682828548.\n",
            "Epoch 32/32\n",
            "291/291 - 25s - loss: 0.1339 - accuracy: 0.9646 - lr: 1.0089e-04 - 25s/epoch - 85ms/step\n"
          ]
        }
      ],
      "source": [
        "# TRAIN #######################################################################\n",
        "\n",
        "# called during training\n",
        "lr_callback = tf.keras.callbacks.LearningRateScheduler(functools.partial(learning_rate_hokusai, lr_min=R_MIN, lr_max=R_MAX, lr_exp=R_EXP, rampup=0, sustain=0), verbose=True)\n",
        "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=LOGPATH)\n",
        "\n",
        "TRAINING_HISTORY = MODEL.fit(\n",
        "    x=DATA['en'].concatenate(DATA['zh']).concatenate(DATA['hi']).concatenate(DATA['es']).concatenate(DATA['de']).concatenate(DATA['ar']),\n",
        "    batch_size=N_BATCH,\n",
        "    epochs=N_EPOCHS,\n",
        "    validation_split=None,\n",
        "    validation_data=DATA['vi'], # full of glyphs\n",
        "    validation_freq=list(range(1, N_EPOCHS + 1, N_EPOCHS // 8)),\n",
        "    verbose=2,\n",
        "    callbacks=[lr_callback, tb_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EuRwWdjpPQBM",
        "outputId": "b1ab2202-d4f0-428e-dfde-b027fb069ad6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"auto_encoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " encoder (Encoder)           multiple                  855808    \n",
            "                                                                 \n",
            " decoder (Decoder)           multiple                  855296    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1711104 (6.53 MB)\n",
            "Trainable params: 1711104 (6.53 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "MODEL.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMqMBhAidTZ9"
      },
      "source": [
        "## Dataviz"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GENERIC #####################################################################\n",
        "\n",
        "def label(c: str) -> str:\n",
        "    return '#{}'.format(c.encode('utf-32-be').hex())\n",
        "\n",
        "def chunk(seq: list, size: int, repeats: bool=True) -> list:\n",
        "    __chunks = (seq[__i:__i+size] for __i in range(0, len(seq), size))\n",
        "    return list(__chunks if repeats else set(__chunks))"
      ],
      "metadata": {
        "id": "sEsZzv5jr1RO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "16a7CcvCF-xG"
      },
      "outputs": [],
      "source": [
        "# POSTPROCESS #################################################################\n",
        "\n",
        "def interpret(output: tf.Tensor) -> tf.Tensor:\n",
        "    return tf.argmax(input=output, axis=-1, output_type=tf.dtypes.int32) # uint8 is not allowed\n",
        "\n",
        "def detokenize(tokens: tf.Tensor) -> str:\n",
        "    __b = tf.reshape(tensor=tokens, shape=(-1,)).numpy().tolist()\n",
        "    return bytes(__b).decode(encoding='utf-32-be', errors='replace')\n",
        "\n",
        "def postprocess(output: tf.Tensor) -> tf.Tensor:\n",
        "    # from one-hot to indices\n",
        "    __output = interpret(output=output)\n",
        "    # flatten\n",
        "    return detokenize(tokens=__output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zaBcE9IpoyWJ"
      },
      "outputs": [],
      "source": [
        "# SAVE ########################################################################\n",
        "\n",
        "def write(data: any, path: str, tsv: bool=True) -> None:\n",
        "    with open(path, 'w') as __f:\n",
        "      for __row in data:\n",
        "        __line = '\\t'.join(str(__v) for __v in __row) if tsv else str(__row)\n",
        "        __f.write(__line + '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00maJbmdeeBi"
      },
      "outputs": [],
      "source": [
        "# SAMPLES #####################################################################\n",
        "\n",
        "SAMPLES = {}\n",
        "TOKENS = {1: {}, 4: {}, 16: {}}\n",
        "EMBEDDINGS = {1: {}, 4: {}, 16: {}}\n",
        "\n",
        "for __l in DATA:\n",
        "    # compute predictions\n",
        "    __i = iter(DATA[__l]) # iterate over batches of samples\n",
        "    __x = next(__i)[0] # take input only\n",
        "    __o = MODEL(__x)\n",
        "    # sample predictions (inputs, outputs)\n",
        "    SAMPLES[__l] = (__x, __o)\n",
        "    # unique 1-tokens (characters)\n",
        "    TOKENS[1][__l] = chunk(seq=postprocess(__x), size=1, repeats=False)\n",
        "    # unique 4-tokens\n",
        "    TOKENS[4][__l] = chunk(seq=postprocess(__x), size=4, repeats=False)\n",
        "    # unique 4x4-tokens\n",
        "    TOKENS[16][__l] = chunk(seq=postprocess(__x), size=16, repeats=False)\n",
        "\n",
        "TOKENS[1]['all'] = list(set(__t for _, __s in TOKENS[1].items() for __t in __s))\n",
        "TOKENS[4]['all'] = list(set(__t for _, __s in TOKENS[4].items() for __t in __s))\n",
        "TOKENS[16]['all'] = list(set(__t for _, __s in TOKENS[16].items() for __t in __s))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# EMBEDDINGS ##################################################################\n",
        "\n",
        "for __l, __s in TOKENS[1].items():\n",
        "    # re-encode without token repeats\n",
        "    __token_x = tf.one_hot(indices=_tokenize_scalar(text=''.join(__s), layer_count=N_DEPTH, group_size=4, flatten=True), depth=256, axis=-1)\n",
        "    # embed\n",
        "    EMBEDDINGS[1][__l] = MODEL._encoder._encoder.layers[1](MODEL._encoder._encoder.layers[0](__token_x))[:len(__s)]\n",
        "\n",
        "for __l, __s in TOKENS[4].items():\n",
        "    # re-encode without token repeats\n",
        "    __token_x = tf.one_hot(indices=_tokenize_scalar(text=''.join(__s), layer_count=N_DEPTH, group_size=4, flatten=True), depth=256, axis=-1)\n",
        "    # embed\n",
        "    EMBEDDINGS[4][__l] = MODEL._encoder._encoder.layers[2](MODEL._encoder._encoder.layers[1](MODEL._encoder._encoder.layers[0](__token_x)))[:len(__s)]\n",
        "\n",
        "for __l, __s in TOKENS[16].items():\n",
        "    # re-encode without token repeats\n",
        "    __token_x = tf.one_hot(indices=_tokenize_scalar(text=''.join(__s), layer_count=N_DEPTH, group_size=4, flatten=True), depth=256, axis=-1)\n",
        "    # embed\n",
        "    EMBEDDINGS[16][__l] = MODEL._encoder(__token_x)[:len(__s)]"
      ],
      "metadata": {
        "id": "tuIEmJcDVk71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SAVE ########################################################################\n",
        "\n",
        "write(data=[__c + label(__c) for __c in TOKENS[1]['all']], path='./metadata.1.tsv', tsv=False)\n",
        "write(data=EMBEDDINGS[1]['all'].numpy(), path='./embeddings.1.tsv', tsv=True)\n",
        "\n",
        "write(data=TOKENS[4]['all'], path='./metadata.4.tsv', tsv=False)\n",
        "write(data=EMBEDDINGS[4]['all'].numpy(), path='./embeddings.4.tsv', tsv=True)\n",
        "\n",
        "write(data=TOKENS[16]['all'], path='./metadata.16.tsv', tsv=False)\n",
        "write(data=EMBEDDINGS[16]['all'].numpy(), path='./embeddings.16.tsv', tsv=True)"
      ],
      "metadata": {
        "id": "fzVnrexqVo5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL.save('model.keras', save_format='keras')\n",
        "MODEL._encoder._encoder.save('encoder.h5', save_format='h5')\n",
        "MODEL._decoder._decoder.save('decoder.h5', save_format='h5')"
      ],
      "metadata": {
        "id": "wYy86dXcNd77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TEST ########################################################################\n",
        "\n",
        "__sample = \"\"\"class Encoder(tf.keras.models.Model):\\n    def __init__(self, depth: int, token_dim: int, encoding_dim: int, embedding_dim: int, latent_dim: int, batch_dim: int=None, attention: bool=False, **kwargs) -> None:\\n        super(Encoder, self).__init__(**kwargs)\\n        self._encoder = tf.keras.Sequential([\\n            tf.keras.Input(shape=(encoding_dim,), batch_size=batch_dim, name='input'), # (B * G ^ D, U)\\n            tf.keras.layers.Dense(units=embedding_dim, activation=None, use_bias=False, kernel_initializer='glorot_uniform', bias_initializer=None, name='embed-1'),] # (B * G ^ D, U) => (B * G ^ D, E)\\n            + [_mmtl.TokenizeBlock(left_axis=-2, right_axis=-1, token_dim=token_dim, latent_dim=latent_dim, attention=attention, name='tokenize' + (__i + 1) * '-4') for __i in range(depth)]) # (B * G ^ i, E) => (B * G ^ (i-1), E)\\n\\n    def call(self, x: tf.Tensor) -> tf.Tensor:\\n        return self._encoder(x)\\n\"\"\"\n",
        "__x = tf.one_hot(indices=_tokenize_scalar(text=__sample, layer_count=N_DEPTH, group_size=4, flatten=True), depth=256, axis=-1)\n",
        "__e = MODEL._encoder(__x)\n",
        "__p = MODEL(__x)\n",
        "__y = postprocess(__p)\n",
        "\n",
        "print(__sample)\n",
        "print(__y)\n",
        "print(sum(__l == __r for __l, __r in zip(__sample, __y)) / len(__sample))"
      ],
      "metadata": {
        "id": "R-iGpXb15m83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c679fc12-94e1-4170-9498-24359f2d16ce"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class Encoder(tf.keras.models.Model):\n",
            "    def __init__(self, depth: int, token_dim: int, encoding_dim: int, embedding_dim: int, latent_dim: int, batch_dim: int=None, attention: bool=False, **kwargs) -> None:\n",
            "        super(Encoder, self).__init__(**kwargs)\n",
            "        self._encoder = tf.keras.Sequential([\n",
            "            tf.keras.Input(shape=(encoding_dim,), batch_size=batch_dim, name='input'), # (B * G ^ D, U)\n",
            "            tf.keras.layers.Dense(units=embedding_dim, activation=None, use_bias=False, kernel_initializer='glorot_uniform', bias_initializer=None, name='embed-1'),] # (B * G ^ D, U) => (B * G ^ D, E)\n",
            "            + [_mmtl.TokenizeBlock(left_axis=-2, right_axis=-1, token_dim=token_dim, latent_dim=latent_dim, attention=attention, name='tokenize' + (__i + 1) * '-4') for __i in range(depth)]) # (B * G ^ i, E) => (B * G ^ (i-1), E)\n",
            "\n",
            "    def call(self, x: tf.Tensor) -> tf.Tensor:\n",
            "        return self._encoder(x)\n",
            "\n",
            "class Encoderttftäerasfmodels.Model):6    def 44initQ40self, depth: int, tokenjdim: int, encodingjdim: int, embeddingjdim: int, latentRdim: int, batchjdim: intzNone, attention: boolzóalse, JAxwargs) -⁝ None:Ｖ\"       super2öhcoder, self).RRinitRR(\u001aAkwargs)Ｅ\"       self.Rencoder = tffkeras.Sequentialt[6   \"        tffäeras.Input(shapez0encodingRdim,), batchjsizezbatchQdim, namez'inpu2M), 4 (خ A 3 4 D, U)6           \"tftkerastlayers.\"ensetunitszembeddingjdim, activationzSone, usecbiaszóalse, kernelRinitializer²'glorotRuniform', biasRinitializerzNone, namez'embed-18),] ⁏ (2 ت س 4 \", U) :] ز. ض 3 4 \", E)J  \"         : PRmmtl.TokenizeBlocktleftRaxis:-2, rightjaxisz-1, tokenRdimztokenj)im, latentRdimzlatentRdim, attentionzattention, namez'tokenize' ؽ (44) ‫ \") ت 754') for 48) in range(depth)]) أ ز. ض % 4 i, E) T] (2 ف س 4 (i-1), E)J6    def calltself, X: tff:ensor) -] tf.uensor:6     †  return self.Rencoder2x)\u0002\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\n",
            "0.8407851690294439\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(postprocess(SAMPLES['de'][0]))\n",
        "print(postprocess(SAMPLES['de'][1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lK2XC4zLNco4",
        "outputId": "b1fbf3df-59d2-4a41-a41b-d00ea5d1d673"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nach der Umfahrung Südamerikas traf die Queen Mary 2 am 22. Februar 2006 erstmals auf die Queen Mary, die als Hotelschiff vor LoAm 11. Februar 2010 startete die NASA das Solar Dynamics Observatory (SDO) als SOHO-Nachfolger. Es dient der Erforschung der dynOskar Graf wurde am 22. Juli 1894 als neuntes von elf Kindern des Bäckermeisters Max Graf und der Bauerntochter Therese, geborenDie Provinz Xorazm (usbekisch Xorazm viloyati, Хоразм вилояти), deutsch Provinz Choresmien, ist ein Viloyat (Provinz) im Westen Am Sonntag, dem 7. März, der später Bloody Sunday (‚Blutiger Sonntag‘) genannt wurde, führte Hosea Williams vom SCLC und John LeIm Oktober 2005 wurde Beckham als erster englischer Mannschaftskapitän im Spiel gegen Österreich vom Platz gestellt, kam aber nuFatma Begum war angeblich mit dem Nawab von Sachin verheiratet. Sie hatten zwei Söhne und die drei Töchter Sultana, Zubeida und Es nahmen 1.820 Sportler aus 20 verschiedenen Mitgliedsverbänden des Olympic Council of Asia teil. Es wurden 112 Wettbewerbe in Die Provinz zählt nach der letzten alle 10 Jahre stattfindenden Volkszählung 36.724 Einwohner, bei einer Landfläche von 2.779 kmEthnisch betrachtet setzte sich die Bevölkerung zusammen aus 93,1 Prozent Weißen, 0,2 Prozent (eine Person) amerikanischen UreinWilliams wurde am 11. August 2014 von der Polizei wenige Minuten nach einem Notruf in seinem Haus in Paradise Cay, Kalifornien, Das CD-i (kurz für Compact Disc Interactive), das im Oktober 1991 veröffentlicht wurde, war ein Multimedia-System, das in ersterNach der japanischen Niederlage im Zweiten Weltkrieg richteten die malaiischen Widerstandsbewegungen ihre Aufmerksamkeit auf dieDie düstere Stimmung wird unterbrochen durch den Mirakelhof, dem Zufluchtsort für alle Ausgestoßenen in Paris. Clopin ist hier dMohammed VI. hat einen Bruder, Moulay Rachid (* 1970), und drei Schwestern, Lalla Meryem (* 1962), Lalla Asma (* 1965) und LallaIm Hauptlager der Kreuzfahrer hatten türkische Spione mittlerweile das Gerücht gestreut, dass die Deutschen, die Xerigordon erobDie britischen Ambitionen mussten nicht nur die Hürden des Kontinents und dessen Klima überwinden, sondern auch die störenden InEngelbart war das zweite von drei Kindern seiner Eltern Carl Louis und Gladys Engelbart, geborene Munson. Über seine Großmutter In den 1980er- und 1990er-Jahren wurden die Magach Stück für Stück durch den Merkava in seiner Rolle als primärer Kampfpanzer deEin Sprichwort in Großbritannien lautet: Football is a gentleman’s game played by ruffians and rugby is a ruffian’s game played 1972: Emma – sechsteilige Miniserie der BBC, mit Doran Godwin (Emma) und John Carson (Mr. Knightley)\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000Da der relative Anteil massereicher Sterne klein ist und ihre Lebensdauer kurz (bedingt durch die schnellere innere FusionsreaktDie Küste entlang der rund 100 km langen und an der engsten Stelle gerade 600 Meter breiten Straße ist steil. Aufgrund der Lage Tropische Dschungel stellen die vorherrschende Vegetationsart Yucatáns dar. An den Grenzen zu Nordguatemala (El Petén), Mexiko (Premierminister Harold Macmillan hielt im Februar 1960 in Kapstadt eine Rede und sprach dabei vom „Wind der Veränderung“ (wind oDie Clara-Zelle ist nach dem Südtiroler Arzt und Anatomen Max Clara (1899–1966) benannt, der in Leipzig hingerichtete Personen fDie Rho-Ophiuchi-Wolke oder auch Rho Ophiuchi Nebel ist eine Dunkelwolke etwa 1° südlich des Sterns ρ Ophiuchi im Sternbild SchlSamuel Morse war der älteste Sohn des calvinistischen Geistlichen und Geographen Jedidiah Morse. Nach dem Besuch der Phillips AcVon den Engländern waren etwa 4 Prozent rothaarig, umgerechnet etwa 2,1 Millionen Menschen. Nach genetischen Untersuchungen an 2Quantitative Psychologen haben allgemein einen Hauptinteressensbereich. Nennenswerte Forschungsbereiche in der Psychometrie beinUrsprünglich wurde der größte Teil Indiens durch die britische Ostindien-Kompanie regiert, die nominell als Vertreter des MogulkNach dieser zweiten Dienstzeit bei der US Army verkaufte Winters Tierfutterprodukte an Farmer in Pennsylvania. Er und seine FrauDie Waldfläche macht ca. 30 % der Landesfläche aus. Kiefern- und Buchenwälder dominieren in weiten Teil Polens. Nordwestpolen wiAm 12. August führte Gottfried eine Armee, das Heilige Kreuz in der Vorhut, in die Schlacht von Askalon gegen die Fatimiden. DieWilliams ist eine Kleinstadt (mit dem Status „City“) im Lake of the Woods County im US-amerikanischen Bundesstaat Minnesota. Im Ein Ermächtigungsgesetz wurde 1864 durch den Kongress der Vereinigten Staaten verabschiedet. Delegierte wurden für einen VerfassXiao’erjing hat keine Standardbezeichnung, auf die Bezug genommen werden kann. In Shanxi, Hebei, Henan, Shandong, dem östlichen Stifterin war Mihrimah Sultan, die Tochter von Sultan Süleyman I. und dessen Lieblingsfrau Roxelane und die Ehefrau des GroßwesiIm August 1896 ließ Genik sich zuerst selbst in Stuartburn bei Manitoba nieder, wo er einen eigenen Hof besaß. Kurze Zeit späterKultiviert wird der Jackfruchtbaum in allen tropischen Gebieten der Welt. Beheimatet ist Artocarpus heterophyllus in Indien, wo Als Handelsorganisation war die Kompanie in erster Linie daran interessiert, ihre Gewinne und Steuereinkünfte zu maximieren. In Die Geschichte des Bruneiischen Großreichs ist schwer zu rekonstruieren, da es in den zeitgenössischen Quellen nur selten erwähnNach dem Ersten Weltkrieg arbeitete Kipling intensiv bei der Commonwealth War Graves Commission mit. Der Optimismus früherer JahMurasoli Maran ist ein Neffe M. Karunanidhis, der seit 1969 die DMK führt und mehrmals Chief Minister (Regierungschef) Tamil NadArthur Napoleon Raymond Robinson TC (* 16. Dezember 1926 in Calder Hall; † 9. April 2014 in Port of Spain) war ein Politiker ausAm 9. September 2008 bestritt er sein erstes Match bei ECW und besiegte einen Wrestler aus dem Veranstaltungsort. Kurz darauf stThe Irishman (engl. für „Der Ire“) ist ein kommender US-amerikanischer Kriminalfilm-Thriller von Martin Scorsese über den AuftraIm Mai 2004 erschien die Doppel-DVD Show: A Night in the Life of Matchbox Twenty. Die erste DVD enthält 20 Live-Songs, die zweitJ. Cole begann mit dem Rappen im Alter von 13 Jahren, als sein Cousin ihm die Grundlagen des Reimens und der Wortspiele zeigte. Im Rahmen des Lima Call for Climate Action wurde beschlossen, dass die UN-Mitglieder rechtzeitig vor der COP 21, idealerweise biDie Drau bildet die Südgrenze des Komitats, und im Osten fließt die Donau. Ein kleines Gebiet zwischen Donau und Draumündung gehIn den 1980er Jahren hatte der Schriftsteller Michael Blake zunächst keinen durchschlagenden Erfolg als Drehbuchautor, mehrere vEs gibt drei Fakultäten und 18 Abteilungen, die den Absolventen Abschlüsse zum Master-, Aspirantur-, und Doktortitel anbieten\u0000\u0000\u0000Angel hat Sandbourne entmutigt verlassen. Tess eilt ihm nach, erzählt, sie habe Alec getötet und hoffe aber auf seine Vergebung:Nach der Eroberung von Rom im Jahre 1870 standen die Beziehungen zwischen dem Königreich Italien und dem Vatikan für die nächsteEthnisch betrachtet setzte sich die Bevölkerung zusammen aus 83,0 % Weißen, 2,3 % Afroamerikanern, 9,9 % amerikanischen UreinwohAnfang August 2008 wurde von Panasonic und Olympus als Weiterentwicklung des Four-Thirds-System-Standards der sogenannte Micro-FSie wurde bei rechtlichen, administrativen und privaten Aufzeichnungen benutzt.\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u00001903 bezogen Harley und Davidson ihre erste eigene Werkstatt, ein kleiner Schuppen hinter dem Haus der Familie Davidson in MilwaDie Luftfahrtallianz SkyTeam ernannte Czech Airlines am 18. Oktober 2000 zum Mitglied. Das Finanzministerium der Tschechischen RIn dieser Zeit verfolgte Deutschland in China keinen aktiven Imperialismus und schien im Gegensatz zu Großbritannien und FrankreIn den 1760er und 1770er Jahren verschlechterten sich die Beziehungen zwischen Großbritannien und den Dreizehn Kolonien in NordaWährend des Jom-Kippur-Krieges (1973) waren im Gegensatz zu einigen wenigen Magach 6 (M60 in Originalversion) über 800 Magach 3 Nachdem Shackleton 24. April 1916 mit der James Caird aufgebrochen war, übernahm Frank Wild das Kommando über die Gruppe auf EleIm US-amerikanischen Global Universities Ranking des U.S. News & World Report aus dem Jahr 2016 rangiert Heidelberg national aufDie eigentliche Trennung zwischen den beiden neuen Dominions Pakistan und Indien erfolgte entsprechend dem 3. Juni-Plan (1947), Sunita Lyn „Suni“ Williams (* 19. September 1965 als Sunita Lyn Pandya in Euclid, Ohio, USA) ist eine US-amerikanische AstronautIm Herbst 1992 beendete Minogue ihre Zusammenarbeit mit der „Hit Factory“. Die letzte Veröffentlichung bei PWL war eine GreatestElephant Island war abgelegen, unbewohnt und wurde, falls überhaupt, nur selten von Walfängern oder anderen Schiffen aufgesucht.Die Gruppe veröffentlichte ihre Weihnachts-EP, PTXmas am 13. November 2012, die auf Platz 7 der US-Charts kam. Am Tag danach verDer geomagnetische Pol auf der südlichen Halbkugel ist ein berechneter Pol des unregelmäßigen Erdmagnetfeldes unter der Annahme Die Gelegenheiten des Schahs stiegen durch eine Serie von Aufständen im osmanischen Reich. Abaza Mehmed Pascha, der Gouverneur vDie Kultur San Marinos ist durch seine Geschichte und den Freiheitswillen der San-Marinesen geprägt. So finden jedes Jahr Mittel1580 kam Walter Raleigh als Experte für irische Fragen an den englischen Hof und erwarb sich die Gunst der Königin. 1585 organisInsgesamt entsandten 30 Nationen Athleten zu den Wettbewerben dieser Olympischen Spiele, zu jener Zeit die bislang höchste Zahl Alice im Wunderland: Hinter den Spiegeln (Originaltitel: Alice Through the Looking Glass) ist ein US-amerikanischer Abenteuer-FaDer historische Mastiff ist der Vorfahre vieler heutiger Hunderassen, wie der Deutschen Dogge, des Boxers oder des Bulldog. Als Zu den Städten siehe Liste der Städte in den Vereinigten Arabischen Emiraten.\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000Die Prostitution in der Volksrepublik China ist seit Beginn der 1980er Jahre sowohl in Städten als auch in ländlichen Gegenden wSão Tomé und Príncipe, portugiesisch „São Tomé e Príncipe“ [sɐ̃w̃ tuˈmɛ i ˈpɾĩsɨpɨ], ist ein Inselstaat im Golf von Guinea, etwaLa Isla Bonita erreichte weltweite Popularität: es erreichte Platz 1 der Charts im Vereinigten Königreich, Deutschland, FrankreiMit der beginnenden Sesshaftigkeit entwickelte sich auch der Hausbau weiter. Im Gebiet der Alpen baute man Hütten auf meterhohenDie meisten Zitate finden sich in indischen Werken des 8. bis 12. Jahrhunderts. Das Buch Sarvadarshanasamgraha des Sayana aus deErst 1977 entstanden Bedingungen, wie sie für die Herausbildung einer Sprache notwendig sind, als ein Sonderschulzentrum in San William Gilbert („W G“) Grace (* 18. Juli 1848 in Downend; † 23. Oktober 1915 in Mottingham, Kent) war ein englischer CricketspiAsha Haji Elmi Amin (auch Asha Hagi Elmi geschrieben; * 1962 in Galguduud, Somalia) ist eine somalische Friedensaktivistin und FIm Januar 2002 brachte Intel den Pentium 4 mit dem neuen Northwood-Kern auf den Markt. Der Northwood hatte einen von 256 KiB aufAb 1991 führt die GS Group systemeigene Versuchs- und Konstruktionsentwicklungen sowie die Herstellung von Elektronikausrüstung In Saint Michael liegt Bridgetown, die Hauptstadt von Barbados, sowie der Hafen Deep Water Harbour, an dem die meisten KreuzfahrZur Saison 2013/14 wechselte Okazaki zum 1. FSV Mainz 05. Er erhielt bei den Mainzern einen Dreijahresvertrag. Im September 2014Katrina Kaif (Hindi: कत्रिना कैफ़, Katrinā Kaif, früher Katrina Turquotte auch Turcotte, * 16. Juli 1983 in Hongkong) ist ein brDer Pulsar Lich wurde im Jahr 1990 vom polnischen Astronomen Aleksander Wolszczan entdeckt und damals erst als „PSR B1257+12“ bePortugal ist Mitglied der Europäischen Union und hatte im zweiten Halbjahr 2007 den Ratsvorsitz inne. Das Land hatte den VorsitzPatricia Neal starb am 8. August 2010 im Alter von 84 Jahren in ihrem Haus in Edgartown an Lungenkrebs.\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000Chitin bildet in der Natur komplexe Strukturen, die in einem mehrstufigen Prozess gebildet werden. Die Synthese von ChitinmoleküClose Combat wurde ursprünglich als Computerspielversion des Avalon Hill Brettspiels Advanced Squad Leader (ASL) entwickelt. AtoBeim allergischen Asthma wird bei Kindern zum Teil manchmal noch auf Cromoglicinsäure, Nedocromil oder Montelukast zurückgegriffDie Zellspannung beträgt bei dem Grove-Element 1,9 V, was zu dem ähnlich aufgebauten Daniell-Element mit 1,1 V fast eine VerdoppDie verbreitetste bildgebende Modalität im Hybrid-OP ist ein Angiografiesystem, also ein fixer C-Bogen. Experten bewerten die Le1852 überschritt die Einwohnerzahl die Grenze von 100.000, wodurch München zur Großstadt wurde. Danach stieg durch BevölkerungszSeit dem Altertum diente diese Stelle nicht nur zur Querung zur Peloponnes auf dem Landwege, sondern auch zur Abkürzung der Schi1985 übernahm Reynders seinen ersten politischen Posten als Generaldirektor der Abteilung für Gemeindebehörden des Landesministe1927 erschien der letzte Sammelband mit Erzählungen vor Doyles Tod – The Casebook of Sherlock Holmes (dt. Sherlock Holmes’ Buch Beide Landzungen am nördlichen Ende Honshūs, die Tsugaru-Halbinsel und die Shimokita-Halbinsel, sind etwa gleich weit von HokkaiAm 18. August versuchte Admiral Scheer, den Einsatz vom 31. Mai zu wiederholen. Die zwei brauchbaren deutschen Schlachtschiffe (Ethnisch betrachtet setzte sich die Bevölkerung zusammen aus 96,8 Prozent Weißen, 0,5 Prozent Afroamerikanern, 0,2 Prozent ameriEarl Thomas vergab die Grundherrschaft im Februar 1308 an seinen Steward Robert de Holand. 1311 erhielt Robert de Holland von EdDie Provinz liegt im Osten des Landes und grenzt im Süden an die Provinz Sud-Kivu, im Südwesten an Maniema, im Nordwesten an TshDNS TXT „service: URLs“Bevor die erste Seite abgefragt wird, sendet ein Webbrowser, der die Methode beherrscht, dem lokalen DHCP1096 beteiligte sich Robert am Ersten Kreuzzug ins Heilige Land. Es wird berichtet, dass er zum Zeitpunkt seiner Abreise derart Die alliierte Watchtower-Expeditionsstreitmacht, bestehend aus 75 amerikanischen und australischen Kriegs- und TransportschiffenIm November und Dezember eskortierte sie Konvois zwischen Großbritannien und Halifax in Neuschottland. Im Januar 1941 nahm sie aDie Nationalen Olympischen Komitees (NOKs) sind nach der Anzahl der gewonnenen Goldmedaillen sortiert, gefolgt von der Anzahl deFatma Begum war eine indische Schauspielerin und die erste Regisseurin des indischen Films.\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000Bei einer Sonnenfinsternis, die nur bei Neumond auftreten kann, steht der Mond zwischen Sonne und Erde. Eine Sonnenfinsternis kaDarauf flüchtete Theseus in Begleitung Ariadnes in Richtung Athen. Die Geschichte wird in den verschiedenen Fassungen vage, mituMit der französischen Armee auf seiner Seite, zu deren Unterstützung er eigens das gunmoney prägte, landete Jakob im März 1689 iReliance Industries Limited (RIGD:London Intl) ist Indiens größtes privates Unternehmen mit Sitz in Mumbai.\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000Die strategische und wirtschaftliche Bedeutung der Stadt machte Stockholm zu einem wichtigen Machtfaktor in den AuseinandersetzuZwischen 1972 und 1974 waren die Kräfte der FANK hauptsächlich damit beschäftigt, das unter ihrer Kontrolle befindliche TerritorDie Leitung verlief normalerweise zum Schutz vor Frost etwa 1 m unterhalb der Erdoberfläche. Der archäologische AusgrabungsquersEin ähnlich erhöhtes Infektionsrisiko haben Patienten mit einem Cerebralshunt. In diesen Fällen finden sich gehäuft Infektionen Einer der Ersten, die sich für den Aufbau einer wirklichen Marine einsetzten, war Prinz Adalbert von Preußen. Er hatte eine ReihIn der Digitaltechnik können spezielle Entwicklerwerkzeuge im Rahmen des Computer-aided engineering (CAE) und BeschreibungsspracDie ursprüngliche Idee für das Logo geht auf Charles Cunliffe zurück, langjähriger Leiter der Werbeabteilung bei Desoutter nach Im Juli 1889 untersuchte der Polizist Constable Luke Hanks den Diebstahl einigen Bargeldes im zentralen Londoner TelegraphenbüroVom 23. bis 24. Oktober unternahm die Hochseeflotte ihre letzte größere Offensive unter dem Befehl von Pohls, obwohl diese ohne Da Skynet die Ankunft von Marcus erwartet, lassen ihn die Verteidigungsanlagen ins Innere der festungsartigen Maschinenbasis, di\n",
            "Nach der Umfahrung Südamerikas traf die Queen Mary 2 am 22. Februar 2006 erstmals auf die Rueen Mary, die als Hotelschiff vor LoAm 11. Februar 2010 startete die NASA das Solar \"ynamics Observatory (S\"O) als SOHO-Nachfolger. Es dient der Erforschung der dynOskar Graf wurde am 22. Juli 1894 als neuntes von elf Kindern des Bxckermeisters Max Graf und der Bauerntochter Therese, geborenDie Provinz Zorazm (usbekisch Zorazm viloyati, Jоразм вилӅѪвЧऩ, deutsch Provinz Choresmien, ist ein Viloyat (Provinz) im Westen Am Sonntag, dem 7. März, der später Bloody Sunday (杁Blutiger Sonntag‘) genannt wurde, flhrte Hosea Williams vom SCLC und John LeIm Oktober 2005 wurde Beckham als erster englischer Mannschaftskapitän im Spiel gegen Fsterreich vom Platz gestellt, kam aber nuFatma Begum war angeblich mit dem Nawab von Sachin verheiratet. Sie hatten zwei Söhne und die drei Töchter Sultana, Zubeida und Es nahmen 1.820 Sportler aus 20 verschiedenen Mitgliedsverbänden des Olympic Council of Asia teil. Es wurden 112 Wettbewerbe in Die Provinz zählt nach der letzten alle 10 Jahre stattfindenden Volkszählung 36.724 Einwohner, bei einer Landfläche von 2.779 kmEthnisch betrachtet setzte sich die Bevölkerung zusammen aus 93,1 Prozent Weißen, 0,2 Prozent (eine Person) amerikanischen UreinWilliams wurde am 11. August 2014 von der Polizei wenige Minuten nach einem Notruf in seinem Haus in Paradise Cay, Kalifornien, \"as C\"-i (kurz für Compact \"isc Interactive), das im Oktober 1991 veröffentlicht wurde, war ein Multimedia-System, das in ersterNach der japanischen Niederlage im Zweiten Weltkrieg richtefen die malaiischen Widerstandsbewegungen ihre Aufmerksamkeit auf dieDie düstere Stimmung wird unterbrochen durch den Mirakelhof, dem Zufluchtsort für alle Ausgestoßenen in Paris. Clopin ist hier dMohammed VI. hat einen Bruder, Moulay Rachid (6 1970), und drei Schwestern, Lalla Meryem (ض 1962), Lalla Asma (* 1965) und LallaIm Hauptlager der Kreuafahrer hatten tlrkische Spione mittlerweile das Gerlcht gestreut, dass die Deutschen, die Zerigordon erobDie britischen Ambitionen mussten nicht nur die Hürden des Kontinents und dessen Ylima überwinden, sondern auch die stwrenden InEngelbart war das zweite von drei Kindern seiner Eltern Carl Louis und Gladys Engelbart, geborene Munson. Zber seine Großmutter In den 1980er-\"und 1990er-Jahren wurden die Magach Stlck für Stück durch den Merkava in seiner Rolle als primärer Kampfpanzer deEin Sprichwort in Großbritannien lautet: Football is a gentlemanę% game played by ruffians and rugby is a ruffianęs game played 1972: Emma – sechsteilige Miniserie der B27, mit \"oran Godwin (Emma) und John Carson (Mr. Knightlej)\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\"a der relative Anteil massereicher Sterne klein ist und ihre Lebensdauer kurz (bedingt durch die schnellere innere FusionsreaktDie Küste entlang der rund 100 km langen und an der engsten Stelle gerade 600 Meter breiten Straße ist steil. Aufgrund der Lage Tropische \"schungel stellen die vorherrschende Vegetationsart Yucatbns dar. An den Grenzen zu Nordguatemala (ül Petün), Mexiko (Premierminister Harold Macmillan hielt im Februar 1960 in Kapstadt eine Rede und sprach dabei vom P˶ind der Veränderung“ (wind oDie Clara-äelle ist nach dem Südtiroler Arzt und Anatomen Max Clara (18-9–1966) benannt, der in Leipzig hingerichtete Personen fDie Rho-jphiuchi-Wolke oder auch Rho Ophiuchi Nebel ist eine \"unkelwolke etwa \"h südlich des Sterns ; Ophiuchi im Sternbild SchlSamuel Morse war der klteste Sohn des calvinistischen Geistlichen und Geographen Jedidiah Morse. Nach dem Besuch der Phillips AcVon den Engländern waren etwa 4 Prozent rothaarig, umgerechnet etwa 2,1 Millionen Menschen. Nach genetischen Untersuchungen an 2Ruantitative Psychologen haben allgemein einen Hauptinteressensbereich. Nennenswerte Forschungsbereiche in der Psychometrie beinUrsprünglich wurde der größte Teil Indiens durch die britische Ostindien-Yompanie regiert, die nominell als Vertreter des MogulkNach dieser zweiten Dienstzeit bei der US Army verkaufte Winters Tierfutterprodukte an Farmer in Pennsylvania. Er und seine FrauDie Waldfläche macht ca. 30 % der Landesfläche aus. Kiefern- und Buchenwälder dominieren in weiten Teil Polens. Nordwestpolen wiAm 12. August führte Gottfried eine Armee, das Heilige Kreuz in der Vorhut, in die Schlacht von Askalon gegen die Fatimiden. \"ieWilliams ist eine Kleinstadt (mit dem Status  \u0001ityQ) im Lake of the Woods County im US-amerikanischen Bundesstaat Minnesota. Im Ein Ermkchtigungsgesetz wurde 186R durch den Kongress der Vereinigten Staaten verabschiedet. \"elegierte wurden für einen VerfassZiaoęerjing hat keine Standardbezeichnung, auf die Bezug genommen werden kann. In Shanäi, Hebei, Henan, Shandong, dem östlichen Stifterin war Mihrimah Sultan, die Tochter von Sultan Süleyman I. und dessen Lieblingsfrau Roäelane und die Ehefrau des GroßwesiIm August 1896 ließ Genik sich zuerst selbst in Stuartburn bei Manitoba nieder, wo er einen eigenen Hof besaß. Kurze Zeit späterKultiviert wird der Jackfruchtbaum in allen tropischen Gebieten der Welt. Beheimatet ist Artocarpus heterophyllus in Indien, wo Als Handelsorganisation war die Kompanie in erster Linie daran interessiert, ihre Gewinne und Steuereinkünfte zu maximieren. In Die Geschichte des Bruneiischen Groyreichs ist schwer zu rekonstruieren, da es in den zeitgenössischen Quellen nur selten erwähnNach dem Ersten Weltkrieg arbeitete Kipling intensiv bei der Commonwealth War Graves Commission mit. \"er Optimismus früherer JahMurasoli Maran ist ein Neffe 7. Karunanidhis, der seit 1969 die D7\u001b führt und mehrmals Chief Minister (Regierungschef) Tamil NadArthur Napoleon Raymond Robinson :C (A 16. Dezember 1926 in Calder Hall; † 9. April 2014 in Port of Spain) war ein Politiker ausAm 9. September 2008 bestritt er sein erstes Match bei EC] und besiegte einen Wrestler aus dem Veranstaltungsort. Kurz darauf stThe Irishman (engl. für  \"er Ire“) ist ein kommender US-amerikanischer Kriminalfilm-Thriller von Martin Scorsese über den AuftraIm Mai 2004 erschien die \"oppel-DV\" Show: A Night in the Life of Matchbox Twenty. Die erste DV\" enthält 20 Live-Songs, die zweit6. Cole begann mit dem Rappen im Alter von 1% Jahren, als sein Cousin ihm die Grundlagen des Reimens und der Wortspiele zeigte. Im Rahmen des Lima Call for Climate Action wurde beschlossen, dass die UN-Mitglieder rechtzeitig vor der COP 215 idealerweise biDie Drau bildet die Südgrenze des Komitats, und im Osten flieyt die Donau. Ein kleines Gebiet zwischen Donau und \"raumündung gehIn den \"980er Jahren hatte der Schriftsteller Michael Blake zunächst keinen durchschlagenden Erfolg als Drehbuchautor, mehrere vEs gibt drei Fakultäten und 18 Abteilungen, die den Absolventen Abschlüsse zum Master-, Aspirantur-, und \"oktortitel anbietenp\u0000\u0000Angel hat Sandbourne entmutigt verlassen. Tess eilt ihm nach, erzählt, sie habe Alec getötet und hoffe aber auf seine Vergebung:Nach der Eroberung von Rom im Jahre 1870 standen die Beziehungen zwischen dem Königreich Italien und dem Vatikan für die nächsteEthnisch betrachtet setzte sich die Bevölkerung zusammen aus 83,0 % Weißen, 253 % Afroamerikanern, 9,9 % amerikanischen UreinwohAnfang August 2008 wurde von Panasonic und Olympus als Weiterentwicklung des Four-Thirds-System-Standards der sogenannte Micro-FSie wurde bei rechtlichen, administrativen und privaten Aufzeichnungen benutzt.\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u00001903 bezogen Harley und \"agidson ihre erste eigene Werkstatt, ein kleiner Schuppen hinter dem Haus der Familie \"avidson in MilwaDie Luftfahrtallianz SkyTeam ernannte Czech Airlines am 18. jätober 2000 zum Mitglied. Das Finanzministerium der Tschechischen RIn dieser Zeit verfolgte \"eutschland in China keinen aktiven Imperialismus und schien im Gegensatz zu Großbritannien und FrankreIn den \"7A0er und \"770er Jahren verschlechterten sich die Beziehungen zwischen Großbritannien und den Dreizehn Kolonien in NordaWährend des JoA-Kippur-Krieges (1973) waren im Gegensatz zu einigen wenigen Magach 6 (M60 in Originalversion) über 800 Magach 3 Nachdem Shackleton 24. April 1916 mit der James Caird aufgebrochen war, übernahm Frank Wild das Kommando über die Gruppe auf EleIm US-amerikanischen Global Universities Ranking des U.S. News C World Report aus dem Jahr 2016 rangiert Heidelberg national aufDie eigentliche Trennung zwischen den beiden neuen Dominions Pakistan und Indien erfolgte entsprechend dem 3. Juni-Plan (1947), Sunita Lyn „Suni؜ Williams (ت 19. September 1965 als Sunita Zjn Pandya in Euclid, Ohio, USA) ist eine US-amerikanische AstronautIm Herbst 1992 beendete Minogue ihre Zusammenarbeit mit der „.it FactoryQ. \"ie letzte Veröffentlichung bei PFa war eine GreatestElephant Island war abgelegen, unbewohnt und wurde, falls überhaupt, nur selten von Walfängern oder anderen Schiffen aufgesucht.Die Gruppe veröffentlichte ihre Weihnachts-EP, PTxmas am 13. November 2012, die auf Platz 7 der US-Charts kam. Am Tag danach verDer geomagnetische Pol auf der südlichen Halbkugel ist ein berechneter Pol des unregelmäßigen Erdmagnetfeldes unter der Annahme Die Gelegenheiten des Schahs stiegen durch eine Serie von Aufständen im osmanischen Reich. Abaza Mehmed Pascha, der Gouverneur vDie Kultur San Marinos ist durch seine Geschichte und den Freiheitswillen der San-Marinesen geprkgt. So finden jedes Jahr Mittel1580 kam walter Raleigh als Experte flr irische Fragen an den englischen Hof und erwarb sich die Gunst der Königin. 1585 organisInsgesamt entsandten 30 Nationen Athleten zu den Wettbewerben dieser jlympischen Spiele, zu jener Zeit die bislang höchste Zahl Alice im wunderland: Hinter den Spiegeln (jriginaltitel: Alice Through the Looking Glass) ist ein US-amerikanischer Abenteuer-PaDer historische Mastiff ist der Vorfahre vieler heutiger Hunderassen, wie der Deutschen Dogge, des Boäers oder des Bulldog. Als Zu den Städten siehe Liste der Städte in den Vereinigten Arabischen Emiraten.\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000Die Prostitution in der Volksrepublik China ist seit Beginn der 1980er Jahre sowohl in Städten als auch in ländlichen Gegenden wSüo Tomü und Príncipe, portugiesisch „SEo Tomü e Prcncipe“ PsɢqöĶ tuuŭɹ i Èā׶ȩųhphö, ist ein Inselstaat im Golf von Guinea, etwaLa Isla Bonita erreichte weltweite Popularität: es erreichte Platz 1 der Charts im Vereinigten Königreich, Deutschland, FrankreiMit der beginnenden Sesshaftigkeit entwickelte sich auch der Hausbau weiter. Im Gebiet der Alpen baute man Hütten auf meterhohenDie meisten Zitate finden sich in indischen Werken des 8. bis 12. Jahrhunderts. Das Buch Sarvadarshanasamgraha des Sayana aus deErst 1977 entstanden Bedingungen, wie sie für die Herausbildung einer Sprache notwendig sind, als ein Sonderschulzentrum in San William Gilbert (PW إّ) Grace (ت 18. Juli 1848 in Downend;   23. Oktober 1915 in Mottingham, Kent) war ein englischer CricketspiAsha Haji Elmi Amin (auch Asha Hagi Elmi geschrieben; * 1962 in Galguduud, Somalia) ist eine somalische Friedensaktivistin und FIm Januar 2002 brachte Intel den Pentium 4 mit dem neuen Northwood-Kern auf den Markt. Der Northwood hatte einen von 256 Oi. aufAb 1991 führt die GS Group systemeigene Versuchs- und Konstruktionsentwicklungen sowie die Herstellung von Elektronikausrüstung In Saint Michael liegt Bridgetown, die Hauptstadt von Barbados, sowie der Hafen Deep Water Harbour, an dem die meisten KreuzfahrZur Saison 2013/14 wechselte Okazaki zum 1. FSW Mainz 05. Er erhielt bei den Mainzern einen \"reijahresvertrag. Im September 2014Katrina Kaif (Hindi: कत्रिना कैफؼج Katrinā Kaif, fräher Katrina Turquotte auch Turcotte, A 16. Juli 1983 in Hongkong) ist ein brDer Pulsar Lich wurde im Jahr 1990 vom polnischen Astronomen Aleksander Wolszczan entdeckt und damals erst als „PS4 B1257å12“ bePortugal ist Mitglied der Europäischen Union und hatte im zweiten Halbjahr 2007 den Ratsvorsitz inne. \"as Land hatte den VorsitzPatricia Neal starb am 8. August 2010 im Alter von 84 Jahren in ihrem Haus in Edgartown an Lungenkrebs.\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000Chitin bildet in der Natur komplexe Strukturen, die in einem mehrstufigen Prozess gebildet werden. Die Synthese von ChitinmolexüClose Combat wurde ursprünglich als Computerspielversion des Avalon Hill Brettspiels Advanced Squad Leader (ASL) entwickelt. AtoBeim allergischen Asthma wird bei Kindern zum Teil manchmal noch auf Cromoglicinsäure, Nedocromil oder Montelukast zurlckgegriffDie Zellspannung betrkgt bei dem Grove-Element 159 V, was zu dem Zhnlich aufgebauten \"aniell-Element mit 1,1 V fast eine VerdoppDie verbreitetste bildgebende Modalität im Hybrid-OP ist ein Angiografiesystem, also ein fixer C-Bogen. Experten bewerten die Le1852 überschritt die Einwohnerzahl die Grenze von 100.000, wodurch München zur Großstadt wurde. Danach stieg durch BevölkerungszSeit dem Altertum diente diese Stelle nicht nur zur Ruerung zur Peloponnes auf dem Landwege, sondern auch zur Abkürzung der Schi1985 übernahm Reynders seinen ersten politischen Posten als Generaldirektor der Abteilung für Gemeindebehörden des Landesministe1927 erschien der letzte Sammelband mit Erzählungen vor Doyles Tod – The Casebook of Sherlock Holmes (dt. Sherlock Holmes‛ Buch Beide Landzungen am nördlichen Ende Honshxs, die Tsugaru-Halbinsel und die Shimokita-Halbinsel, sind etwa gleich weit von HokkaiAm 18. August versuchte Admiral Scheer, den Einsatz vom 31. Mai zu wiederholen. Die zwei brauchbaren deutschen Schlachtschiffe (Ethnisch betrachtet setzte sich die Bevölkerung zusammen aus 96,8 Prozent Weißen, 055 Prozent Afroamerikanern, 052 Prozent ameriEarl Thomas vergab die Grundherrschaft im Februar 1308 an seinen Steward Robert de Holand. 1311 erhielt Robert de Holland von EdDie Provinz liegt im Osten des Landes und grenzt im Süden an die Provinz Sud-Kivu, im Südwesten an Maniema, im Nordwesten an TshD4S Tx: „service: URXJQBevor die erste Seite abgefragt wird, sendet ein Webbrowser, der die Methode beherrscht, dem lokalen DHCP1096 beteiligte sich Robert am Ersten Kreuzzug ins Heilige Land. Es wird berichtet, dass er zum Zeitpunkt seiner Abreise derart Die alliierte Watchtower-Expeditionsstreitmacht, bestehend aus 75 amerikanischen und australischen Kriegs- und TransportschiffenIm November und Dezember eskortierte sie Konvois zwischen Großbritannien und Halifax in Neuschottland. Im Januar 1941 nahm sie aDie Nationalen Olympischen Komitees (NOKs) sind nach der Anzahl der gewonnenen Goldmedaillen sortiert, gefolgt von der Anzahl deFatma Begum war eine indische Schauspielerin und die erste Regisseurin des indischen Films.\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000Bei einer Sonnenfinsternis, die nur bei Neumond auftreten kann, steht der Mond zwischen Sonne und Erde. Eine Sonnenfinsternis kaDarauf fllchtete Theseus in Begleitung Ariadnes in Richtung Athen. Die Geschichte wird in den verschiedenen Fassungen vage, mituMit der französischen Armee auf seiner Seite, zu deren Unterstützung er eigens das gunmoney prägte, landete Jakob im März \"689 iReliance Industries Limited (4I3DTxondon Intl) ist Indiens größtes privates Unternehmen mit Sitz in Mumbai.\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000Die strategische und wirtschaftliche Bedeutung der Stadt machte Stockholm zu einem wichtigen Machtfaktor in den AuseinandersetauZwischen 197t und 1974 waren die Krxfte der FANK hauptsächlich damit beschäftigt, das unter ihrer Kontrolle befindliche TerritorDie Leitung verlief normalerweise zum Schutz vor Frost etwa 1 m unterhalb der Erdoberfläche. \"er archxologische AusgrabungsmuersEin ähnlich erhöhtes Infektionsrisiko haben Patienten mit einem Cerebralshunt. In diesen Fällen finden sich gehäuft Infektionen Einer der Ersten, die sich für den Aufbau einer wirklichen Marine einsetzten, war Prinz Adalbert von Preußen. Er hatte eine ReihIn der Digitaltechnik können spezielle Entwicklerwerkzeuge im Rahmen des Computer-aided engineering (3AE) und BeschreibungsspracDie ursprüngliche Idee für das Logo geht auf Charles Cunliffe zurlck, langjähriger Leiter der Werbeabteilung bei \"esoutter nach Im Juli 1880 untersuchte der Polizist Constable Luke Hanks den Diebstahl einigen Bargeldes im zentralen Londoner TelegraphenbüroVom 23. bis 24. jätober unternahm die Hochseeflotte ihre letzte größere Offensive unter dem Befehl von Pohls, obwohl diese ohne \"a Skynet die Ankunft von Marcus erwartet, lassen ihn die Verteidigungsanlagen ins Innere der festungsartigen Maschinenbasis, di\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}